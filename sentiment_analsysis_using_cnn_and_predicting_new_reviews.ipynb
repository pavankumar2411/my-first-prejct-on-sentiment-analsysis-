{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analsysis using  cnn  and predicting new reviews.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMl87KljfWgo"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "import datetime\r\n",
        "#import lightgbm as lgb\r\n",
        "from scipy import stats\r\n",
        "from scipy.sparse import hstack, csr_matrix\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\r\n",
        "#from wordcloud import WordCloud\r\n",
        "from collections import Counter\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.util import ngrams\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.multiclass import OneVsRestClassifier\r\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOvXiLTQfcFh"
      },
      "source": [
        "##Reading the input files\r\n",
        "\r\n",
        "train = pd.read_csv('train.tsv', sep=\"\\t\")\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "1Pn0ecOxf1LC",
        "outputId": "bba2f9a7-fa49-446b-8f40-269452c6449e"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "_dDWZlRvf3b7",
        "outputId": "42ada7a9-7490-48a1-fdc7-e1a4456ba099"
      },
      "source": [
        "train.loc[train.SentenceId == 2]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent is worth seeking .</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>This quiet , introspective and entertaining independent</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>66</td>\n",
              "      <td>2</td>\n",
              "      <td>This</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining independent</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet , introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>quiet</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>, introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>71</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and entertaining</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective and</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>73</td>\n",
              "      <td>2</td>\n",
              "      <td>introspective</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>and</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>75</td>\n",
              "      <td>2</td>\n",
              "      <td>entertaining</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>independent</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking .</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>78</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth seeking</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>79</td>\n",
              "      <td>2</td>\n",
              "      <td>is worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>worth</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>seeking</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PhraseId  ...  Sentiment\n",
              "63        64  ...          4\n",
              "64        65  ...          3\n",
              "65        66  ...          2\n",
              "66        67  ...          4\n",
              "67        68  ...          3\n",
              "68        69  ...          2\n",
              "69        70  ...          3\n",
              "70        71  ...          3\n",
              "71        72  ...          3\n",
              "72        73  ...          2\n",
              "73        74  ...          2\n",
              "74        75  ...          4\n",
              "75        76  ...          2\n",
              "76        77  ...          3\n",
              "77        78  ...          4\n",
              "78        79  ...          2\n",
              "79        80  ...          2\n",
              "80        81  ...          2\n",
              "\n",
              "[18 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8kmdO9-0ZkK"
      },
      "source": [
        "Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cNZcBESf8j1"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk import FreqDist\r\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\r\n",
        "stemmer=SnowballStemmer('english')\r\n",
        "lemma=WordNetLemmatizer()\r\n",
        "from string import punctuation\r\n",
        "import re"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFuem23Ul58g",
        "outputId": "67a1cc3f-7297-449a-df90-e6b0675e1ec7"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('popular')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS7DoVuOgjsj"
      },
      "source": [
        "def clean_review(review_col):\r\n",
        "    review_corpus=[]\r\n",
        "    for i in range(0,len(review_col)):\r\n",
        "        review=str(review_col[i])\r\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\r\n",
        "        \r\n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\r\n",
        "        review=' '.join(review)\r\n",
        "        review_corpus.append(review)\r\n",
        "    return review_corpus\r\n",
        "   "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny4ddGu3gsAg"
      },
      "source": [
        "train['clean_review']=clean_review(train.Phrase.values)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "b6IeqAg7iVRo",
        "outputId": "08b8514c-a2cf-4dc7-fb5b-7dba8a5bfd08"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                                                                                                                            clean_review\n",
              "0         1  ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1         2  ...                                                                                                            a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                                                                                                                                a series\n",
              "3         4  ...                                                                                                                                                                                       a\n",
              "4         5  ...                                                                                                                                                                                  series\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA7UGpGdjRmE"
      },
      "source": [
        "##Balancing the data by Resampling\r\n",
        "from sklearn.utils import resample\r\n",
        "train_2 = train[train['Sentiment']==2]\r\n",
        "train_1 = train[train['Sentiment']==1]\r\n",
        "train_3 = train[train['Sentiment']==3]\r\n",
        "train_4 = train[train['Sentiment']==4]\r\n",
        "train_5 = train[train['Sentiment']==0]\r\n",
        "train_2_sample = resample(train_2,replace=True,n_samples=75000,random_state=123)\r\n",
        "train_1_sample = resample(train_1,replace=True,n_samples=75000,random_state=123)\r\n",
        "train_3_sample = resample(train_3,replace=True,n_samples=75000,random_state=123)\r\n",
        "train_4_sample = resample(train_4,replace=True,n_samples=75000,random_state=123)\r\n",
        "train_5_sample = resample(train_5,replace=True,n_samples=75000,random_state=123)\r\n",
        "\r\n",
        "df_upsampled = pd.concat([train_2, train_1_sample,train_3_sample,train_4_sample,train_5_sample])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "xVehWLTqjVZs",
        "outputId": "76517af5-4195-4d59-f453-831fee6dafbf"
      },
      "source": [
        "df_upsampled.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                                                  clean_review\n",
              "1         2  ...  a series of escapade demonstrating the adage that what is good for the goose\n",
              "2         3  ...                                                                      a series\n",
              "3         4  ...                                                                             a\n",
              "4         5  ...                                                                        series\n",
              "5         6  ...           of escapade demonstrating the adage that what is good for the goose\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh82xjdKjX7W"
      },
      "source": [
        "text = ' '.join(df_upsampled.loc[df_upsampled.Sentiment == 4, 'Phrase'].values)\r\n",
        "text_trigrams = [i for i in ngrams(text.split(), 3)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPjeudawjfj1",
        "outputId": "d703abf5-5854-434f-c915-7826f473cbe8"
      },
      "source": [
        "Counter(text_trigrams).most_common(30)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('one', 'of', 'the'), 1644),\n",
              " (('of', 'the', 'year'), 832),\n",
              " (('of', 'the', 'best'), 677),\n",
              " (('of', 'the', 'most'), 612),\n",
              " (('is', 'one', 'of'), 407),\n",
              " (('One', 'of', 'the'), 370),\n",
              " ((',', 'and', 'the'), 333),\n",
              " (('the', 'year', \"'s\"), 326),\n",
              " (('It', \"'s\", 'a'), 323),\n",
              " (('the', 'edge', 'of'), 300),\n",
              " (('it', \"'s\", 'a'), 299),\n",
              " (('a', 'movie', 'that'), 297),\n",
              " (('of', 'your', 'seat'), 273),\n",
              " (('the', 'film', 'is'), 267),\n",
              " (('the', 'kind', 'of'), 267),\n",
              " (('.', 'is', 'a'), 264),\n",
              " (('the', 'film', \"'s\"), 264),\n",
              " (('as', 'one', 'of'), 254),\n",
              " ((',', 'the', 'film'), 253),\n",
              " (('edge', 'of', 'your'), 249),\n",
              " ((',', 'this', 'is'), 236),\n",
              " (('as', 'well', 'as'), 231),\n",
              " ((',', 'it', \"'s\"), 226),\n",
              " (('film', 'that', 'is'), 223),\n",
              " (('.', 'It', \"'s\"), 218),\n",
              " (('a', 'film', 'that'), 211),\n",
              " ((',', 'funny', ','), 208),\n",
              " (('some', 'of', 'the'), 206),\n",
              " (('year', \"'s\", 'best'), 188),\n",
              " (('a', 'solid', 'cast'), 178)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9kyGXasjpCP"
      },
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sZbqGBR1vRO"
      },
      "source": [
        "Applying ML algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa6qYyPTjun-",
        "outputId": "b29171e2-99fe-4167-df02-d79cf7cc2607"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\r\n",
        "full_text = list(df_upsampled['clean_review'].values)\r\n",
        "vectorizer.fit(full_text)\r\n",
        "df_upsampled_vectorized = vectorizer.transform(df_upsampled['clean_review'])\r\n",
        "test_vectorized = vectorizer.transform(train['clean_review'])\r\n",
        "test1 = train['clean_review']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfnpj8tZj8ZC"
      },
      "source": [
        "y = df_upsampled['Sentiment']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_e5ZmX2kWYg"
      },
      "source": [
        "logreg = LogisticRegression()\r\n",
        "ovr = OneVsRestClassifier(logreg)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWFRl7GjkiOf",
        "outputId": "2895390f-603c-4595-807e-de039cdbb700"
      },
      "source": [
        "%%time\r\n",
        "ovr.fit(df_upsampled_vectorized, y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 58.9 s, sys: 1min 4s, total: 2min 3s\n",
            "Wall time: 1min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=100,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=None,\n",
              "                                                 solver='lbfgs', tol=0.0001,\n",
              "                                                 verbose=0, warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl6vM-w9kl5j",
        "outputId": "40b42ddc-b255-4359-aa57-899c96b3723a"
      },
      "source": [
        "scores = cross_val_score(ovr, df_upsampled_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\r\n",
        "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation mean accuracy 72.04%, std 0.43.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLwKc5kpkxoP",
        "outputId": "6d966e93-43b1-4220-f876-11443b10af1e"
      },
      "source": [
        "\r\n",
        "%%time\r\n",
        "svc = LinearSVC(dual=False)\r\n",
        "scores = cross_val_score(svc, df_upsampled_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\r\n",
        "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation mean accuracy 77.44%, std 0.47.\n",
            "CPU times: user 76.4 ms, sys: 40.7 ms, total: 117 ms\n",
            "Wall time: 59.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxz3bHUKk5_r",
        "outputId": "efadd37e-54a0-4a05-8a10-4cacdfb605ce"
      },
      "source": [
        "\r\n",
        "%%time\r\n",
        "model = MultinomialNB()\r\n",
        "#model.fit(train_vectorized, y)\r\n",
        "scores =  cross_val_score(model, df_upsampled_vectorized, y, scoring='accuracy', n_jobs=-1, cv=3)\r\n",
        "print('Cross-validation mean accuracy {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation mean accuracy 59.51%, std 0.16.\n",
            "CPU times: user 72.9 ms, sys: 34.9 ms, total: 108 ms\n",
            "Wall time: 580 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZV-xTuanVfQ",
        "outputId": "cc3aa7bc-32cd-40c0-b429-8db0e554b63b"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "X = df_upsampled['clean_review']\r\n",
        "#test_set = test['clean review']\r\n",
        "#Y = train['Sentiment']\r\n",
        "Y = to_categorical(df_upsampled['Sentiment'].values)\r\n",
        "print(Y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMVThEV0nWQK"
      },
      "source": [
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=123)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBBFGJZUnZ8H",
        "outputId": "51b3b89e-4ff1-4d29-8243-24d2fdab902c"
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\r\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284686,) (284686, 5)\n",
            "(94896,) (94896, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCraGoAng8X"
      },
      "source": [
        "\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLmabP_xnnFi",
        "outputId": "e76b55c1-2860-4b95-8cbf-e1bbeb77623b"
      },
      "source": [
        "##Total number of words/features\r\n",
        "all_words=' '.join(X_train)\r\n",
        "all_words=word_tokenize(all_words)\r\n",
        "#print(all_words)\r\n",
        "dist=FreqDist(all_words)\r\n",
        "\r\n",
        "num_unique_word=len(dist)\r\n",
        "num_unique_word\r\n",
        "#X_train.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRmTjeeinrEY",
        "outputId": "8f5e3db6-36e4-4103-b72d-cbbef71d61f1"
      },
      "source": [
        "##Number of words for each phrase/text\r\n",
        "r_len=[]\r\n",
        "for text in X_train:\r\n",
        "    word=word_tokenize(text)\r\n",
        "  #  print(text)\r\n",
        "    l=len(word)\r\n",
        "    r_len.append(l)\r\n",
        "    \r\n",
        "MAX_REVIEW_LEN=np.max(r_len)\r\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5eSexWGnupE"
      },
      "source": [
        "\r\n",
        "max_features = num_unique_word\r\n",
        "max_words = MAX_REVIEW_LEN\r\n",
        "batch_size = 128\r\n",
        "epochs = 3\r\n",
        "num_classes=5"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQwCI6yYn77Q"
      },
      "source": [
        "\r\n",
        "from tensorflow.python.keras.models import Sequential\r\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\r\n",
        "\r\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bEEB2xD2Abz"
      },
      "source": [
        "Tokenizing the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CVIWAMjn-vS"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\r\n",
        "\r\n",
        "X_test = tokenizer.texts_to_sequences(test1)\r\n",
        "#X_test"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifhbcC69oKLk"
      },
      "source": [
        "from keras.preprocessing import sequence,text\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYcFAnLoO5o",
        "outputId": "20da1054-d9dd-4255-bb3e-2534f95d0b71"
      },
      "source": [
        "from keras.preprocessing import sequence,text\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\r\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\r\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\r\n",
        "#print(X_train.shape,X_val.shape)\r\n",
        "X_test"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     4,     2,    41],\n",
              "       [    0,     0,     0, ...,    14,     1,  4890],\n",
              "       [    0,     0,     0, ...,     0,     2,   334],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     0, 10416, 10417],\n",
              "       [    0,     0,     0, ...,     0,     0, 10416],\n",
              "       [    0,     0,     0, ...,     0,     0, 10417]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvGNGVH_tJpJ"
      },
      "source": [
        "CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI7PW1CNoSxk"
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\r\n",
        "from keras.layers import SpatialDropout1D\r\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\r\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-HNs0Dioi6N"
      },
      "source": [
        "model2 = Sequential()\r\n",
        "\r\n",
        "# Input / Embdedding\r\n",
        "model2.add(Embedding(max_features, 150, input_length=max_words))\r\n",
        "\r\n",
        "# CNN\r\n",
        "model2.add(SpatialDropout1D(0.2))\r\n",
        "\r\n",
        "model2.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\r\n",
        "model2.add(MaxPooling1D(pool_size=2))\r\n",
        "\r\n",
        "model2.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\r\n",
        "model2.add(MaxPooling1D(pool_size=2))\r\n",
        "\r\n",
        "model2.add(Flatten())\r\n",
        "\r\n",
        "# Output layer\r\n",
        "model2.add(Dense(5, activation='sigmoid'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQnU8Cdool7e",
        "outputId": "f14f7f8f-f40c-45a0-c53f-04142915d80f"
      },
      "source": [
        "\r\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model2.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2225/2225 [==============================] - 57s 22ms/step - loss: 1.0697 - accuracy: 0.5440 - val_loss: 0.6934 - val_accuracy: 0.7221\n",
            "Epoch 2/3\n",
            "2225/2225 [==============================] - 50s 22ms/step - loss: 0.6241 - accuracy: 0.7512 - val_loss: 0.5931 - val_accuracy: 0.7684\n",
            "Epoch 3/3\n",
            "2225/2225 [==============================] - 49s 22ms/step - loss: 0.5067 - accuracy: 0.8020 - val_loss: 0.5334 - val_accuracy: 0.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49c51397b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Udx03SstOtH"
      },
      "source": [
        "predictions \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUUbuaj6oqMM",
        "outputId": "9a97db9c-21c2-4b73-a43d-55c678c1abca"
      },
      "source": [
        "pred2=model2.predict_classes(X_test,verbose=1)\r\n",
        "\r\n",
        "\r\n",
        "#sub.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  92/4877 [..............................] - ETA: 8s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4877/4877 [==============================] - 8s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r_XJTGrpa1N",
        "outputId": "fbfa8f67-af9d-4f2f-aba9-f4fbd4bd5d78"
      },
      "source": [
        "pred2"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, ..., 3, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMGj_yXLpllP"
      },
      "source": [
        "###testingfor new reviews\r\n",
        "text1 = \"This movie is fantastic! I really like it because it is so good!\"\r\n",
        "text2 = \"Good movie!\"\r\n",
        "text3 = \"Maybe I like this movie.\"\r\n",
        "text4 = \"Meh ...\"\r\n",
        "text5 = \"If I were a drunk teenager then this movie might be good.\"\r\n",
        "text6 = \"Bad movie!\"\r\n",
        "text7 = \"Not a good movie!\"\r\n",
        "text8 = \"This movie really sucks! Can I get my money back please?\"\r\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6--gxvprDM"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ28AGm4ptl4",
        "outputId": "30efb4b6-fe3d-42c7-a294-a934a22eca91"
      },
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=MAX_REVIEW_LEN)\r\n",
        "tokens_pad.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 48)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VumeolqtpxCn",
        "outputId": "fa94fd13-66c7-4948-b0df-86585ab6d5b5"
      },
      "source": [
        "pred3=model2.predict_classes(tokens_pad,verbose=1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nPSlnDCp3uk",
        "outputId": "ed0de945-4152-43a5-c20c-1c0a0ee7a29e"
      },
      "source": [
        "print(pred3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 4 2 2 1 0 2 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1pCZrDmqUAM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}